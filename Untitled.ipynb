{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T14:22:17.667365Z",
     "start_time": "2018-05-27T14:22:17.173402Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T14:22:18.135771Z",
     "start_time": "2018-05-27T14:22:18.128207Z"
    }
   },
   "outputs": [],
   "source": [
    "a = LexicalRichness('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T07:24:04.700517Z",
     "start_time": "2018-05-09T07:24:04.681362Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexicalrichness.lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T14:19:41.055998Z",
     "start_time": "2018-05-27T14:19:41.032210Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T14:20:22.900148Z",
     "start_time": "2018-05-27T14:20:21.786394Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexicalrichness import lexicalrichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T14:20:35.162968Z",
     "start_time": "2018-05-27T14:20:35.156151Z"
    }
   },
   "outputs": [],
   "source": [
    "from lexicalrichness.lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T07:22:53.467836Z",
     "start_time": "2018-05-09T07:22:52.832635Z"
    }
   },
   "outputs": [],
   "source": [
    "%run tests/test_lexicalrichness.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T07:24:26.219544Z",
     "start_time": "2018-05-09T07:24:25.326719Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"Tests for `lexicalrichness` package.\"\"\"\n",
    "\n",
    "\n",
    "import unittest\n",
    "\n",
    "# from lexicalrichness.lexicalrichness import LexicalRichness\n",
    "from lexicalrichness.lexicalrichness import *\n",
    "import textblob\n",
    "\n",
    "\n",
    "class TestLexicalrichness(unittest.TestCase):\n",
    "    \"\"\"Tests for `lexicalrichness` package.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        print('setting up')\n",
    "        self.s1 = \"TEST text with some text numbers 42, hyphen-here, and text punctuations.\"\n",
    "        self.s2 = \"TEST text with some text numbers 42, hyphen–here, and text punctuations.\"\n",
    "        self.s3 = \"TEST text with some text numbers 42, hyphen—here, and text punctuations.\"\n",
    "        self.emptystring = ''\n",
    "\n",
    "        self.obj1 = LexicalRichness(self.s1)\n",
    "        self.obj2 = LexicalRichness(self.s2)\n",
    "        self.obj3 = LexicalRichness(self.s3)\n",
    "        self.emptyobj = LexicalRichness(self.emptystring)\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('tearing down\\n')\n",
    "\n",
    "    def test_preprocess(self):\n",
    "        print('testing preprocess')\n",
    "\n",
    "        self.assertEqual(preprocess(self.s1), 'test text with some text numbers , hyphenhere, and text punctuations.')\n",
    "        self.assertEqual(preprocess(self.s2), 'test text with some text numbers , hyphenhere, and text punctuations.')\n",
    "        self.assertEqual(preprocess(self.s3), 'test text with some text numbers , hyphenhere, and text punctuations.')\n",
    "        self.assertEqual(preprocess(self.emptystring), '')\n",
    "\n",
    "    def test_tokenize(self):\n",
    "        print('testing tokenize')\n",
    "\n",
    "        self.assertIs(type(tokenize(self.s1)), list)\n",
    "        self.assertIs(type(tokenize(self.s2)), list)\n",
    "        self.assertIs(type(tokenize(self.s3)), list)\n",
    "        self.assertIs(type(tokenize(self.emptystring)), list)\n",
    "\n",
    "    def test_blobber(self):\n",
    "        print('testing blobber')\n",
    "\n",
    "        self.assertIs(type(blobber(self.s1)), textblob.blob.WordList)\n",
    "        self.assertIs(type(blobber(self.s2)), textblob.blob.WordList)\n",
    "        self.assertIs(type(blobber(self.s3)), textblob.blob.WordList)\n",
    "        self.assertIs(type(blobber(self.emptystring)), textblob.blob.WordList)\n",
    "\n",
    "    def test_list_sliding_window(self):\n",
    "        print('testing list_sliding_window')\n",
    "\n",
    "        test_list = ['a', 'b', 'c', 'd']\n",
    "\n",
    "        self.assertEqual(list(list_sliding_window(test_list, 1)), [('a',), ('b',), ('c',), ('d',)])\n",
    "        self.assertEqual(list(list_sliding_window(test_list, 2)), [('a', 'b'), ('b', 'c'), ('c', 'd')])\n",
    "        self.assertEqual(list(list_sliding_window(test_list, 3)), [('a', 'b', 'c'), ('b', 'c', 'd')])\n",
    "        self.assertEqual(list(list_sliding_window(test_list, 4)), [('a', 'b', 'c', 'd')])\n",
    "\n",
    "    def test_segment_generator(self):\n",
    "        print('testing segment_generator')\n",
    "\n",
    "        test_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "        self.assertEqual(list(segment_generator(test_list, 3)), [[1,2,3], [4,5,6], [7,8,9], [10]])\n",
    "        self.assertEqual(list(segment_generator(test_list, 5)), [[1,2,3,4,5], [6,7,8,9,10]])\n",
    "        self.assertEqual(list(segment_generator(test_list, 1)), [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "        self.assertEqual(list(segment_generator(test_list, 10)), [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "        self.assertEqual(list(segment_generator(test_list, 11)), [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "\n",
    "    def test_words(self):\n",
    "        print('testing words')\n",
    "        self.assertEqual(self.obj1.words, 10)\n",
    "        self.assertEqual(self.emptyobj.words, 0)\n",
    "\n",
    "    def test_terms(self):\n",
    "        print('testing terms')\n",
    "        self.assertEqual(self.obj1.terms, 8)\n",
    "        self.assertEqual(self.emptyobj.terms, 0)\n",
    "\n",
    "    def test_ttr(self):\n",
    "        print('testing ttr')\n",
    "        self.assertEqual(self.obj1.ttr, 0.8)\n",
    "\n",
    "    def test_rttr(self):\n",
    "        print('testing rttr')\n",
    "        self.assertEqual(self.obj1.rttr, 2.5298221281347035)\n",
    "\n",
    "    def test_cttr(self):\n",
    "        print('testing cttr')\n",
    "        self.assertEqual(self.obj1.cttr, 1.7888543819998317)\n",
    "\n",
    "    def test_Herdan(self):\n",
    "        print('testing Herdan')\n",
    "        self.assertEqual(self.obj1.Herdan, 0.9030899869919434)\n",
    "\n",
    "    def test_Summer(self):\n",
    "        print('testing Summer')\n",
    "        self.assertEqual(self.obj1.Summer, 0.8777828395738175)\n",
    "\n",
    "    def test_Dugast(self):\n",
    "        print('testing Dugast')\n",
    "        self.assertEqual(self.obj1.Dugast, 23.760032854423635)\n",
    "\n",
    "    def test_Maas(self):\n",
    "        print('testing Maas')\n",
    "        self.assertEqual(self.obj1.Maas, 0.04208748389057132)\n",
    "\n",
    "    def test_msttr(self):\n",
    "        print('testing msttr')\n",
    "\n",
    "        self.assertEqual(self.obj1.msttr(segment_window=5, discard=True), 0.8)\n",
    "        self.assertEqual(self.obj1.msttr(segment_window=5, discard=False), 0.9)\n",
    "\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.msttr(segment_window=0)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.msttr(segment_window=-1)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.msttr(segment_window=1.5)\n",
    "\n",
    "    def test_mattr(self):\n",
    "        print('testing mattr')\n",
    "\n",
    "        self.assertEqual(self.obj1.mattr(window_size=5), 0.9)\n",
    "        self.assertEqual(self.obj1.mattr(window_size=1), 1)\n",
    "        self.assertEqual(self.obj1.mattr(window_size=self.obj1.words), self.obj1.ttr)\n",
    "\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.mattr(window_size=0)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.mattr(window_size=-1)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.mattr(window_size=1.5)\n",
    "\n",
    "    def test_mtld(self):\n",
    "        print('testing mtld')\n",
    "\n",
    "        self.assertEqual(self.obj1.mtld(threshold=0.72), 14.000000000000004)\n",
    "\n",
    "        all_unqiue = LexicalRichness('only unique terms in this little string')\n",
    "        self.assertEqual(all_unqiue.mtld(threshold=0.72), all_unqiue.words)\n",
    "\n",
    "    def test_hdd(self):\n",
    "        print('testing hdd')\n",
    "\n",
    "        self.assertEqual(self.obj1.hdd(draws=5), 0.8833333333333332)\n",
    "\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.hdd(draws=0)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.hdd(draws=-5)\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.obj1.hdd(draws=1.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T07:24:26.236801Z",
     "start_time": "2018-05-09T07:24:26.229445Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
