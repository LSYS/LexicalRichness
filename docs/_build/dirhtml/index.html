<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LexicalRichness &mdash; LexicalRichness  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="#" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex/" />
    <link rel="search" title="Search" href="search/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="#" class="icon icon-home"> LexicalRichness
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">LexicalRichness</a><ul>
<li><a class="reference internal" href="#installation">1. Installation</a></li>
<li><a class="reference internal" href="#quickstart">2. Quickstart</a></li>
<li><a class="reference internal" href="#use-lexicalrichness-in-your-own-pipeline">3. Use LexicalRichness in your own pipeline</a></li>
<li><a class="reference internal" href="#using-with-pandas">4. Using with Pandas</a></li>
<li><a class="reference internal" href="#attributes">5. Attributes</a></li>
<li><a class="reference internal" href="#methods">6. Methods</a></li>
<li><a class="reference internal" href="#formulation-algorithmic-details">7. Formulation &amp; Algorithmic Details</a></li>
<li><a class="reference internal" href="#example-use-cases">8. Example use cases</a></li>
<li><a class="reference internal" href="#contributing">9. Contributing</a></li>
<li><a class="reference internal" href="#citing">10. Citing</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">LexicalRichness</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>LexicalRichness</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="lexicalrichness">
<h1>LexicalRichness<a class="headerlink" href="#lexicalrichness" title="Permalink to this headline"></a></h1>
<div class="line-block">
<div class="line"><a class="reference external" href="https://pypi.org/project/lexicalrichness/"><img alt="pypi" src="https://badge.fury.io/py/lexicalrichness.svg" /></a> <a class="reference external" href="https://anaconda.org/conda-forge/lexicalrichness"><img alt="conda-forge" src="https://img.shields.io/conda/vn/conda-forge/lexicalrichness" /></a> <a class="reference external" href="https://github.com/LSYS/LexicalRichness/releases"><img alt="latest-release" src="https://img.shields.io/github/v/release/lsys/lexicalrichness" /></a> <a class="reference external" href="https://img.shields.io/pypi/pyversions/lexicalrichness"><img alt="python-ver" src="https://img.shields.io/pypi/pyversions/lexicalrichness" /></a></div>
<div class="line"><a class="reference external" href="https://github.com/LSYS/LexicalRichness/actions/workflows/build.yml"><img alt="ci-status" src="https://github.com/LSYS/LexicalRichness/actions/workflows/build.yml/badge.svg?branch=master" /></a> <a class="reference external" href="https://GitHub.com/Naereen/StrapDown.js/graphs/commit-"><img alt="maintained" src="https://img.shields.io/badge/Maintained%3F-yes-green.svg" /></a> <a class="reference external" href="http://makeapullrequest.com"><img alt="PRs" src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" /></a> <a class="reference external" href="https://www.codefactor.io/repository/github/lsys/lexicalrichness"><img alt="codefactor" src="https://www.codefactor.io/repository/github/lsys/lexicalrichness/badge" /></a> <a class="reference external" href="https://lgtm.com/projects/g/LSYS/LexicalRichness/context:python"><img alt="lgtm" src="https://img.shields.io/lgtm/grade/python/g/LSYS/LexicalRichness.svg?logo=lgtm&amp;logoWidth=18)" /></a></div>
<div class="line"><a class="reference external" href="https://github.com/LSYS/LexicalRichness/blob/master/LICENSE"><img alt="license" src="https://img.shields.io/github/license/LSYS/LexicalRichness?color=blue&amp;label=License" /></a> <a class="reference external" href="https://mybinder.org/v2/gh/LSYS/lexicaldiversity-example/main?labpath=example.ipynb"><img alt="mybinder" src="https://mybinder.org/badge_logo.svg" /></a> <a class="reference external" href="https://doi.org/10.5281/zenodo.6607007"><img alt="zenodo" src="https://zenodo.org/badge/DOI/10.5281/zenodo.6607007.svg" /></a></div>
</div>
<p><a class="reference external" href="https://github.com/lsys/lexicalrichness">LexicalRichness</a> is a small Python module to compute textual lexical richness (aka lexical diversity) measures.</p>
<p>Lexical richness refers to the range and variety of vocabulary deployed in a text by a speaker/writer (McCarthy and Jarvis 2007). Lexical richness is used interchangeably with lexical diversity, lexical variation, lexical density, and vocabulary richness and is measured by a wide variety of indices. Uses include (but not limited to) measuring writing quality, vocabulary knowledge (Šišková 2012), speaker competence, and socioeconomic status (McCarthy and Jarvis 2007).</p>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title"><strong>Table of Contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#installation" id="id4">1. Installation</a></p></li>
<li><p><a class="reference internal" href="#quickstart" id="id5">2. Quickstart</a></p></li>
<li><p><a class="reference internal" href="#use-lexicalrichness-in-your-own-pipeline" id="id6">3. Use LexicalRichness in your own pipeline</a></p></li>
<li><p><a class="reference internal" href="#using-with-pandas" id="id7">4. Using with Pandas</a></p></li>
<li><p><a class="reference internal" href="#attributes" id="id8">5. Attributes</a></p></li>
<li><p><a class="reference internal" href="#methods" id="id9">6. Methods</a></p></li>
<li><p><a class="reference internal" href="#formulation-algorithmic-details" id="id10">7. Formulation &amp; Algorithmic Details</a></p></li>
<li><p><a class="reference internal" href="#example-use-cases" id="id11">8. Example use cases</a></p></li>
<li><p><a class="reference internal" href="#contributing" id="id12">9. Contributing</a></p></li>
<li><p><a class="reference internal" href="#citing" id="id13">10. Citing</a></p></li>
</ul>
</div>
<section id="installation">
<h2><a class="toc-backref" href="#id4">1. Installation</a><a class="headerlink" href="#installation" title="Permalink to this headline"></a></h2>
<p><strong>Install using PIP</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install lexicalrichness
</pre></div>
</div>
<p>If you encounter,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ne">ModuleNotFoundError</span><span class="p">:</span> <span class="n">No</span> <span class="n">module</span> <span class="n">named</span> <span class="s1">&#39;textblob&#39;</span>
</pre></div>
</div>
<p>install textblob:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install textblob
</pre></div>
</div>
<p><em>Note</em>: This error should only exist for <code class="code docutils literal notranslate"><span class="pre">versions</span> <span class="pre">&lt;=</span> <span class="pre">v0.1.3</span></code>. Fixed in
<a class="reference external" href="https://github.com/LSYS/LexicalRichness/releases/tag/0.1.4">v0.1.4</a> by <a class="reference external" href="https://github.com/davidlesieur">David Lesieur</a> and <a class="reference external" href="https://github.com/cbedetti">Christophe Bedetti</a>.</p>
<p><strong>Install from Conda-Forge</strong></p>
<p><em>LexicalRichness</em> is now also available on conda-forge. If you have are using the <a class="reference external" href="https://www.anaconda.com/distribution/#download-section">Anaconda</a> or <a class="reference external" href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a> distribution, you can create a conda environment and install the package from conda.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda create -n lex
conda activate lex
conda install -c conda-forge lexicalrichness
</pre></div>
</div>
<p><em>Note</em>: If you get the error <code class="code docutils literal notranslate"><span class="pre">CommandNotFoundError:</span> <span class="pre">Your</span> <span class="pre">shell</span> <span class="pre">has</span> <span class="pre">not</span> <span class="pre">been</span> <span class="pre">properly</span> <span class="pre">configured</span> <span class="pre">to</span> <span class="pre">use</span> <span class="pre">'conda</span> <span class="pre">activate'</span></code> with <code class="code docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">lex</span></code> in <em>Bash</em> either try</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">bash</span></code> in the <em>Anaconda Prompt</em> and then retry <code class="code docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">lex</span></code> in <em>Bash</em></p></li>
<li><p>or just try <code class="code docutils literal notranslate"><span class="pre">source</span> <span class="pre">activate</span> <span class="pre">lex</span></code> in <em>Bash</em></p></li>
</ul>
</div></blockquote>
<p><strong>Install manually using Git and GitHub</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/LSYS/LexicalRichness.git
<span class="nb">cd</span> LexicalRichness
pip install .
</pre></div>
</div>
<p><strong>Run from the cloud</strong></p>
<p>Try the package on the cloud (without setting anything up on your local machine) by clicking the icon here:</p>
<p><a class="reference external" href="https://mybinder.org/v2/gh/LSYS/lexicaldiversity-example/main?labpath=example.ipynb"><img alt="mybinder" src="https://mybinder.org/badge_logo.svg" /></a></p>
</section>
<section id="quickstart">
<h2><a class="toc-backref" href="#id5">2. Quickstart</a><a class="headerlink" href="#quickstart" title="Permalink to this headline"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">lexicalrichness</span> <span class="kn">import</span> <span class="n">LexicalRichness</span>

<span class="go"># text example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Measure of textual lexical diversity, computed as the mean length of sequential words in</span>
<span class="go">                a text that maintains a minimum threshold TTR score.</span>

<span class="go">                Iterates over words until TTR scores falls below a threshold, then increase factor</span>
<span class="go">                counter by 1 and start over. McCarthy and Jarvis (2010, pg. 385) recommends a factor</span>
<span class="go">                threshold in the range of [0.660, 0.750].</span>
<span class="go">                (McCarthy 2005, McCarthy and Jarvis 2010)&quot;&quot;&quot;</span>

<span class="go"># instantiate new text object (use the tokenizer=blobber argument to use the textblob tokenizer)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span> <span class="o">=</span> <span class="n">LexicalRichness</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="go"># Return word count.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">words</span>
<span class="go">57</span>

<span class="go"># Return (unique) word count.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">terms</span>
<span class="go">39</span>

<span class="go"># Return type-token ratio (TTR) of text.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">ttr</span>
<span class="go">0.6842105263157895</span>

<span class="go"># Return root type-token ratio (RTTR) of text.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">rttr</span>
<span class="go">5.165676192553671</span>

<span class="go"># Return corrected type-token ratio (CTTR) of text.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">cttr</span>
<span class="go">3.6526846651686067</span>

<span class="go"># Return mean segmental type-token ratio (MSTTR).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">msttr</span><span class="p">(</span><span class="n">segment_window</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="go">0.88</span>

<span class="go"># Return moving average type-token ratio (MATTR).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">mattr</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="go">0.8351515151515151</span>

<span class="go"># Return Measure of Textual Lexical Diversity (MTLD).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">mtld</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.72</span><span class="p">)</span>
<span class="go">46.79226361031519</span>

<span class="go"># Return hypergeometric distribution diversity (HD-D) measure.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">hdd</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="go">0.7468703323966486</span>

<span class="go"># Return Herdan&#39;s lexical diversity measure.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">Herdan</span>
<span class="go">0.9061378160786574</span>

<span class="go"># Return Summer&#39;s lexical diversity measure.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">Summer</span>
<span class="go">0.9294460323356605</span>

<span class="go"># Return Dugast&#39;s lexical diversity measure.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">Dugast</span>
<span class="go">43.074336212149774</span>

<span class="go"># Return Maas&#39;s lexical diversity measure.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lex</span><span class="o">.</span><span class="n">Maas</span>
<span class="go">0.023215679867353005</span>
</pre></div>
</div>
</section>
<section id="use-lexicalrichness-in-your-own-pipeline">
<h2><a class="toc-backref" href="#id6">3. Use LexicalRichness in your own pipeline</a><a class="headerlink" href="#use-lexicalrichness-in-your-own-pipeline" title="Permalink to this headline"></a></h2>
<p><code class="code docutils literal notranslate"><span class="pre">LexicalRichness</span></code> comes packaged with minimal preprocessing + tokenization for a quick start.</p>
<p>But for intermediate users, you likely have your preferred <code class="code docutils literal notranslate"><span class="pre">nlp_pipeline</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your preferred preprocessing + tokenization pipeline</span>
<span class="k">def</span> <span class="nf">nlp_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">return</span> <span class="n">list_of_tokens</span>
</pre></div>
</div>
<p>Use <code class="code docutils literal notranslate"><span class="pre">LexicalRichness</span></code> with your own <code class="code docutils literal notranslate"><span class="pre">nlp_pipeline</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initiate new LexicalRichness object with your preprocessing pipeline as input</span>
<span class="n">lex</span> <span class="o">=</span> <span class="n">LexicalRichness</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">preprocesser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">nlp_pipeline</span><span class="p">)</span>

<span class="c1"># Compute lexical richness</span>
<span class="n">mtld</span> <span class="o">=</span> <span class="n">lex</span><span class="o">.</span><span class="n">mtld</span><span class="p">()</span>
</pre></div>
</div>
<p>Or use <code class="code docutils literal notranslate"><span class="pre">LexicalRichness</span></code> at the end of your pipeline and input the <code class="code docutils literal notranslate"><span class="pre">list_of_tokens</span></code> with <code class="code docutils literal notranslate"><span class="pre">preprocesser=None</span></code> and <code class="code docutils literal notranslate"><span class="pre">tokenizer=None</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Preprocess the text</span>
<span class="n">list_of_tokens</span> <span class="o">=</span> <span class="n">nlp_pipeline</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Initiate new LexicalRichness object with your list of tokens as input</span>
<span class="n">lex</span> <span class="o">=</span> <span class="n">LexicalRichness</span><span class="p">(</span><span class="n">list_of_tokens</span><span class="p">,</span> <span class="n">preprocesser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Compute lexical richness</span>
<span class="n">mtld</span> <span class="o">=</span> <span class="n">lex</span><span class="o">.</span><span class="n">mtld</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="using-with-pandas">
<h2><a class="toc-backref" href="#id7">4. Using with Pandas</a><a class="headerlink" href="#using-with-pandas" title="Permalink to this headline"></a></h2>
<p>Here’s a minimal example using <cite>lexicalrichness</cite> with a <cite>Pandas</cite> <cite>dataframe</cite> with a column containing text:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mtld</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">lex</span> <span class="o">=</span> <span class="n">LexicalRichness</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lex</span><span class="o">.</span><span class="n">mtld</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;mtld&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">mtld</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="attributes">
<h2><a class="toc-backref" href="#id8">5. Attributes</a><a class="headerlink" href="#attributes" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 23%" />
<col style="width: 77%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">wordlist</span></code></p></td>
<td><p>list of words</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">words</span></code></p></td>
<td><p>number of words (w)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">terms</span></code></p></td>
<td><p>number of unique terms (t)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">preprocessor</span></code></p></td>
<td><p>preprocessor used</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tokenizer</span></code></p></td>
<td><p>tokenizer used</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ttr</span></code></p></td>
<td><p>type-token ratio computed as t / w (Chotlos 1944, Templin 1957)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">rttr</span></code></p></td>
<td><p>root TTR computed as t / sqrt(w) (Guiraud 1954, 1960)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cttr</span></code></p></td>
<td><p>corrected TTR computed as t / sqrt(2w) (Carrol 1964)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Herdan</span></code></p></td>
<td><p>log(t) / log(w) (Herdan 1960, 1964)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Summer</span></code></p></td>
<td><p>log(log(t)) / log(log(w)) Summer (1966)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Dugast</span></code></p></td>
<td><p>(log(w) ** 2) / (log(w) - log(t) Dugast (1978)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Maas</span></code></p></td>
<td><p>(log(w) - log(t)) / (log(w) ** 2) Maas (1972)</p></td>
</tr>
</tbody>
</table>
</section>
<section id="methods">
<h2><a class="toc-backref" href="#id9">6. Methods</a><a class="headerlink" href="#methods" title="Permalink to this headline"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 23%" />
<col style="width: 77%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">msttr</span></code></p></td>
<td><p>Mean segmental TTR (Johnson 1944)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mattr</span></code></p></td>
<td><p>Moving average TTR (Covington 2007, Covington and McFall 2010)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mtld</span></code></p></td>
<td><p>Measure of Lexical Diversity (McCarthy 2005, McCarthy and Jarvis 2010)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hdd</span></code></p></td>
<td><p>HD-D (McCarthy and Jarvis 2007)</p></td>
</tr>
</tbody>
</table>
<p><strong>Assessing method docstrings</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">inspect</span>

<span class="go"># docstring for hdd (HD-D)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getdoc</span><span class="p">(</span><span class="n">LexicalRichness</span><span class="o">.</span><span class="n">hdd</span><span class="p">))</span>

<span class="go">Hypergeometric distribution diversity (HD-D) score.</span>

<span class="go">For each term (t) in the text, compute the probabiltiy (p) of getting at least one appearance</span>
<span class="go">of t with a random draw of size n &lt; N (text size). The contribution of t to the final HD-D</span>
<span class="go">score is p * (1/n). The final HD-D score thus sums over p * (1/n) with p computed for</span>
<span class="go">each term t. Described in McCarthy and Javis 2007, p.g. 465-466.</span>
<span class="go">(McCarthy and Jarvis 2007)</span>

<span class="go">Parameters</span>
<span class="go">__________</span>
<span class="go">draws: int</span>
<span class="go">    Number of random draws in the hypergeometric distribution (default=42).</span>

<span class="go">Returns</span>
<span class="go">_______</span>
<span class="go">float</span>
</pre></div>
</div>
<p>Alternatively, just do</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">lex</span><span class="o">.</span><span class="n">hdd</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="go">Hypergeometric distribution diversity (HD-D) score.</span>

<span class="go">    For each term (t) in the text, compute the probabiltiy (p) of getting at least one appearance</span>
<span class="go">    of t with a random draw of size n &lt; N (text size). The contribution of t to the final HD-D</span>
<span class="go">    score is p * (1/n). The final HD-D score thus sums over p * (1/n) with p computed for</span>
<span class="go">    each term t. Described in McCarthy and Javis 2007, p.g. 465-466.</span>
<span class="go">    (McCarthy and Jarvis 2007)</span>

<span class="go">    Parameters</span>
<span class="go">    ----------</span>
<span class="go">    draws: int</span>
<span class="go">        Number of random draws in the hypergeometric distribution (default=42).</span>

<span class="go">    Returns</span>
<span class="go">    -------</span>
<span class="go">    float</span>
</pre></div>
</div>
</section>
<section id="formulation-algorithmic-details">
<h2><a class="toc-backref" href="#id10">7. Formulation &amp; Algorithmic Details</a><a class="headerlink" href="#formulation-algorithmic-details" title="Permalink to this headline"></a></h2>
<p>For now, refer to the study below for algorithmic details:</p>
<blockquote>
<div><p>Shen, Lucas (2021). Measuring political media using text data.
(<a class="reference external" href="https://www.lucasshen.com/research/media.pdf">https://www.lucasshen.com/research/media.pdf</a>)</p>
<details>
<summary><a>Click here for citation metadata</a></summary><div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@techreport</span><span class="p">{</span><span class="nl">accuracybias</span><span class="p">,</span>
<span class="na">title</span><span class="p">=</span><span class="s">{Measuring Political Media Slant Using Text Data}</span><span class="p">,</span>
<span class="na">author</span><span class="p">=</span><span class="s">{Shen, Lucas}</span><span class="p">,</span>
<span class="na">url</span><span class="p">=</span><span class="s">{https://www.lucasshen.com/research/media.pdf}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="example-use-cases">
<h2><a class="toc-backref" href="#id11">8. Example use cases</a><a class="headerlink" href="#example-use-cases" title="Permalink to this headline"></a></h2>
<ul>
<li><p><a class="reference external" href="https://doi.org/10.1007/s10579-021-09562-4">[1]</a> <strong>SENTiVENT</strong> used the metrics that LexicalRichness provides to estimate the classification difficulty of annotated categories in their corpus (Jacobs &amp; Hoste 2020). The metrics show which categories will be more difficult for modeling approaches that rely on linguistic inputs because greater lexical diversity means greater data scarcity and more need for generalization. (h/t Gilles Jacobs)</p>
<blockquote>
<div><p>Jacobs, Gilles, and Véronique Hoste. “SENTiVENT: enabling supervised information extraction of company-specific events in economic and financial news.” Language Resources and Evaluation (2021): 1-33.</p>
<details>
<summary><a>Click here for citation metadata</a></summary><div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">jacobs2021sentivent</span><span class="p">,</span>
<span class="na">title</span><span class="p">=</span><span class="s">{SENTiVENT: enabling supervised information extraction of company-specific events in economic and financial news}</span><span class="p">,</span>
<span class="na">author</span><span class="p">=</span><span class="s">{Jacobs, Gilles and Hoste, V{\&#39;e}ronique}</span><span class="p">,</span>
<span class="na">journal</span><span class="p">=</span><span class="s">{Language Resources and Evaluation}</span><span class="p">,</span>
<span class="na">pages</span><span class="p">=</span><span class="s">{1--33}</span><span class="p">,</span>
<span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
<span class="na">publisher</span><span class="p">=</span><span class="s">{Springer}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><div class="line-block">
<div class="line"><a class="reference external" href="https://www.lucasshen.com/research/media.pdf">[2]</a> <strong>Measuring political media using text data.</strong> This chapter of my thesis investigates whether political media bias manifests by coverage accuracy. As covaraites, I use characteristics of the text data (political speech and news article transcripts). One of the ways speeches can be characterized is via lexical richness.</div>
</div>
<blockquote>
<div><details>
<summary><a>Shen, Lucas (2021). Measuring political media using text data [Click for metadata]</a></summary><div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@techreport</span><span class="p">{</span><span class="nl">accuracybias</span><span class="p">,</span>
<span class="na">title</span><span class="p">=</span><span class="s">{Measuring Political Media Slant Using Text Data}</span><span class="p">,</span>
<span class="na">author</span><span class="p">=</span><span class="s">{Shen, Lucas}</span><span class="p">,</span>
<span class="na">url</span><span class="p">=</span><span class="s">{https://www.lucasshen.com/research/media.pdf}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><a class="reference external" href="https://github.com/notnews/unreadable_news">[3]</a> <strong>Unreadable News: How Readable is American News?</strong> This study characterizes modern news by readability and lexical richness. Focusing on the NYT, they find increasing readability and lexical richness, suggesting that NYT feels competition from alternative sources to be accessible while maintaining its key demographic of college-educated Americans.</p>
<blockquote>
<div><details>
<summary><a>NYT's lexical superiority?</a></summary>

     <p align="left">
             <img width="45%" src="https://raw.githubusercontent.com/lsys/lexicalrichness/master/images/boxplot_lex_nyt_cnn_npr_msnbc.png">
             <br>
             Source: <a href="https://github.com/notnews/unreadable_news">(https://github.com/notnews/unreadable_news)</a>
     </p></div></blockquote>
</li>
</ul>
</section>
<section id="contributing">
<h2><a class="toc-backref" href="#id12">9. Contributing</a><a class="headerlink" href="#contributing" title="Permalink to this headline"></a></h2>
<p><strong>Author</strong></p>
<p><a class="reference external" href="https://www.lucasshen.com/">Lucas Shen</a></p>
<p><strong>Contributors</strong></p>
<a class="reference external image-reference" href="https://github.com/lsys/lexicalrichness/graphs/contributors"><img alt="https://contrib.rocks/image?repo=lsys/lexicalrichness" src="https://contrib.rocks/image?repo=lsys/lexicalrichness" /></a>
<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.
See here for <a class="reference external" href="./CONTRIBUTING.rst">how to contribute</a> to this project.
See here for <a class="reference external" href="http://contributor-covenant.org/version/1/0/0/">Contributor Code of
Conduct</a>.</p>
</section>
<section id="citing">
<h2><a class="toc-backref" href="#id13">10. Citing</a><a class="headerlink" href="#citing" title="Permalink to this headline"></a></h2>
<p>If you have used this codebase and wish to cite it, please cite as below.</p>
<p>Codebase:</p>
<div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">lex</span><span class="p">,</span>
<span class="na">author</span> <span class="p">=</span> <span class="s">{Shen, Lucas}</span><span class="p">,</span>
<span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.6607007}</span><span class="p">,</span>
<span class="na">license</span> <span class="p">=</span> <span class="s">{MIT license}</span><span class="p">,</span>
<span class="na">title</span> <span class="p">=</span> <span class="s">{{LexicalRichness: A small module to compute textual lexical richness}}</span><span class="p">,</span>
<span class="na">url</span> <span class="p">=</span> <span class="s">{https://github.com/LSYS/lexicalrichness}</span><span class="p">,</span>
<span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Documentation on formulations and algorithms:</p>
<div class="highlight-bib notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span><span class="nl">accuracybias</span><span class="p">,</span>
<span class="na">title</span><span class="p">=</span><span class="s">{Measuring Political Media Slant Using Text Data}</span><span class="p">,</span>
<span class="na">author</span><span class="p">=</span><span class="s">{Shen, Lucas}</span><span class="p">,</span>
<span class="na">url</span><span class="p">=</span><span class="s">{https://www.lucasshen.com/research/media.pdf}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The package is released under the <a class="reference external" href="https://opensource.org/licenses/MIT">MIT
License</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Lucas Shen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>